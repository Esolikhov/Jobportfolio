# --- –£–°–¢–ê–ù–û–í–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô ---
!apt-get -y install tesseract-ocr libtesseract-dev tesseract-ocr-rus tesseract-ocr-eng
!wget -O /usr/share/tesseract-ocr/4.00/tessdata/tgk.traineddata https://github.com/tesseract-ocr/tessdata/raw/main/tgk.traineddata
!pip install --upgrade gradio pdfplumber pillow

# --- –ò–ú–ü–û–†–¢–´ ---
import gradio as gr
import pytesseract
from PIL import Image
import pdfplumber
import re

# --- –Ø–ó–´–ö–ò –î–õ–Ø –û–†–° ---
LANG_MAP = {
    "–†—É—Å—Å–∫–∏–π": "rus",
    "–¢–∞–¥–∂–∏–∫—Å–∫–∏–π": "tgk",
    "–ê–Ω–≥–ª–∏–π—Å–∫–∏–π": "eng",
    "–ê–≤—Ç–æ (—Ä—É—Å+—Ç–∞–¥–∂+–∞–Ω–≥–ª)": "rus+tgk+eng"
}

# --- OCR ---
def extract_text(file, lang):
    if file.name.lower().endswith(".pdf"):
        with pdfplumber.open(file.name) as pdf:
            text = ""
            for page in pdf.pages:
                img = page.to_image(resolution=300)
                text += pytesseract.image_to_string(img.original, lang=lang) + "\n"
        return text
    else:
        image = Image.open(file.name)
        text = pytesseract.image_to_string(image, lang=lang)
        return text

# --- –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –ü–û–õ–ï–ô ---
def normalize_label(label):
    label = label.lower()
    replace_map = {
        "–Ω–æ–º–µ—Ä —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏": "transaction_id",
        "transaction id": "transaction_id",
        "–Ω–æ–º–µ—Ä –æ–ø–µ—Ä–∞—Ü–∏–∏": "transaction_id",
        "—Å—á—ë—Ç –∑–∞—á–∏—Å–ª–µ–Ω–∏—è": "account_to",
        "account to": "account_to",
        "—Å—á–µ—Ç –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è": "account_from",
        "from account": "account_from",
        "—Å—á–µ—Ç –ø–æ–ª—É—á–∞—Ç–µ–ª—è": "account_to",
        "to account": "account_to",
        "–¥–∞—Ç–∞ –∏ –≤—Ä–µ–º—è": "datetime",
        "–¥–∞—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏": "date",
        "–≤—Ä–µ–º—è –æ–ø–µ—Ä–∞—Ü–∏–∏": "time",
        "–¥–∞—Ç–∞": "date",
        "–≤—Ä–µ–º—è": "time",
        "—Å—É–º–º–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏": "amount",
        "—Å—É–º–º–∞": "amount",
        "–∏—Ç–æ–≥–æ": "total",
        "–∫–æ–º–∏—Å—Å–∏—è": "commission",
        "—Å–ø–æ—Å–æ–± –æ–ø–ª–∞—Ç—ã": "payment_method",
        "—Å—Ç–∞—Ç—É—Å": "status",
        "comment": "comment",
        "–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π": "comment",
        "–∏–Ω–Ω": "inn",
        "–±–∏–∫": "bik",
        "–ª–∏—Ü–µ–Ω–∑–∏—è": "license",
        "–ø–æ–ª—É—á–∞—Ç–µ–ª—å": "recipient",
        "–ø–æ—Å—Ç–∞–≤—â–∏–∫": "recipient",
        "—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π –ø–ª–∞—Ç–µ–∂": "is_electronic",
        "–∏—Å–ø–æ–ª–Ω–µ–Ω–æ": "status",
        "—É—Å–ø–µ—à–Ω—ã–π": "status",
        "–æ–ø–ª–∞—á–µ–Ω–æ": "status",
    }
    for k, v in replace_map.items():
        if k in label:
            return v
    return label.replace(":", "").replace(".", "").replace(" ", "_")

# --- –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ü–ê–†–°–ï–† –ß–ï–ö–û–í ---
def universal_parse(text):
    result = {}
    lines = text.splitlines()
    for line in lines:
        # –ù–∞—Ö–æ–¥–∏–º –ø–∞—Ä—ã "–ú–µ—Ç–∫–∞: –ó–Ω–∞—á–µ–Ω–∏–µ" –∏–ª–∏ "Label - Value"
        m = re.match(r"\s*([\w\s\.\:‚Ññ\(\)\*]+)[\:\-\‚Äî]\s*(.+)", line, re.IGNORECASE)
        if not m:
            # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ "Label Value"
            m = re.match(r"\s*([\w\s\.\:‚Ññ\(\)\*]+)\s+([^\s]+)", line, re.IGNORECASE)
        if m:
            label = normalize_label(m.group(1).strip())
            value = m.group(2).strip()
            if label in result:
                result[label] += ', ' + value
            else:
                result[label] = value
        else:
            # –°–º–æ—Ç—Ä–∏–º —Å—Ç–∞—Ç—É—Å, –¥–∞—Ç—ã, —Å—É–º–º—ã –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ —Ä–µ–≥—É–ª—è—Ä–∫–∞–º–∏
            if re.search(r"—É—Å–ø–µ—à–Ω(—ã–π|–æ)|–∏—Å–ø–æ–ª–Ω–µ–Ω–æ|paid|–æ–ø–ª–∞—á–µ–Ω–æ|operation done|success", line, re.IGNORECASE):
                result["status"] = "SUCCESS"
            elif re.search(r"\d{4}\-\d{2}\-\d{2}", line):  # 2025-07-02
                result["date"] = line.strip()
            elif re.search(r"\d{2}:\d{2}(:\d{2})?", line):
                result["time"] = line.strip()
            elif re.search(r"[0-9]+\s*[—Åc]", line):
                result["amount"] = line.strip()
    # "–¥–∞—Ç–∞ –∏ –≤—Ä–µ–º—è"
    if "datetime" in result:
        dt = result.pop("datetime")
        parts = dt.split(",")
        if len(parts) == 2:
            result["date"] = parts[0].strip()
            result["time"] = parts[1].strip()
    # –ù–∞—Ö–æ–¥–∏–º —Å—á–µ—Ç–∞/—Ç–µ–ª–µ—Ñ–æ–Ω—ã/–∫–∞—Ä—Ç—ã (12+ —Ü–∏—Ñ—Ä –ø–æ–¥—Ä—è–¥, –µ—Å–ª–∏ –µ—â—ë –Ω–µ –Ω–∞–π–¥–µ–Ω–æ)
    m = re.search(r'\b(\d{12,})\b', text)
    if m and "account_to" not in result:
        result["account_to"] = m.group(1)
    return result

def parse_check(text):
    parsed = universal_parse(text)
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø–æ–ª—è ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
    if not parsed or len(parsed) < 2:
        return {"raw_text": text.strip()}
    return parsed

# --- –û–°–ù–û–í–ù–û–ô GRADIO –ò–ù–¢–ï–†–§–ï–ô–° ---
def process(file, lang_sel):
    lang = LANG_MAP[lang_sel]
    text = extract_text(file, lang)
    parsed = parse_check(text)
    return parsed, text

with gr.Blocks() as demo:
    gr.Markdown("## üßæ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —á–µ–∫–æ–≤ –¢–∞–¥–∂–∏–∫–∏—Å—Ç–∞–Ω–∞ (PDF, JPG, PNG, –ª—é–±—ã–µ –±–∞–Ω–∫–∏)")
    with gr.Row():
        file_in = gr.File(label="–ó–∞–≥—Ä—É–∑–∏—Ç–µ —á–µ–∫ (PDF –∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)", file_types=["image", ".pdf"], type="filepath")
        lang_sel = gr.Radio(list(LANG_MAP.keys()), value="–ê–≤—Ç–æ (—Ä—É—Å+—Ç–∞–¥–∂+–∞–Ω–≥–ª)", label="–Ø–∑—ã–∫ –¥–ª—è OCR")
    with gr.Row():
        json_out = gr.JSON(label="JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
        text_out = gr.Textbox(label="–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç", lines=15)
    btn_clear = gr.Button("Clear")
    btn_submit = gr.Button("Submit")
    btn_submit.click(
        process,
        inputs=[file_in, lang_sel],
        outputs=[json_out, text_out]
    )
    btn_clear.click(
        lambda: ({}, ""), None, [json_out, text_out]
    )

demo.launch(share=True)
